{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f46632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 11:02:24,105 | INFO | Successfully loaded OpenAI API key.\n",
      "2025-08-26 11:02:24,133 | INFO | Starting text extraction from 'PGR_Ohio_BNIC-134120828_trimmed.pdf'...\n",
      "2025-08-26 11:02:24,144 | INFO | Found 72 pages in the document.\n",
      "2025-08-26 11:02:24,927 | INFO |   - No text found on page 68.\n",
      "2025-08-26 11:02:24,956 | INFO | Text extraction complete.\n",
      "2025-08-26 11:02:24,956 | INFO | Starting page classification process...\n",
      "2025-08-26 11:02:24,958 | INFO | Classifying page 1/72...\n",
      "2025-08-26 11:02:26,151 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:26,159 | INFO | Classifying page 2/72...\n",
      "2025-08-26 11:02:27,168 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:27,185 | INFO | Classifying page 3/72...\n",
      "2025-08-26 11:02:28,172 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:28,187 | INFO | Classifying page 4/72...\n",
      "2025-08-26 11:02:29,632 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:29,636 | INFO | Classifying page 5/72...\n",
      "2025-08-26 11:02:30,555 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:30,556 | INFO | Classifying page 6/72...\n",
      "2025-08-26 11:02:31,677 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:31,694 | INFO | Classifying page 7/72...\n",
      "2025-08-26 11:02:32,507 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:32,510 | INFO | Classifying page 8/72...\n",
      "2025-08-26 11:02:34,247 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:34,248 | INFO | Classifying page 9/72...\n",
      "2025-08-26 11:02:35,883 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:35,885 | INFO | Classifying page 10/72...\n",
      "2025-08-26 11:02:37,729 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:37,745 | INFO | Classifying page 11/72...\n",
      "2025-08-26 11:02:38,648 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:38,652 | INFO | Classifying page 12/72...\n",
      "2025-08-26 11:02:40,187 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:40,200 | INFO | Classifying page 13/72...\n",
      "2025-08-26 11:02:41,591 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:41,604 | INFO | Classifying page 14/72...\n",
      "2025-08-26 11:02:42,493 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:42,505 | INFO | Classifying page 15/72...\n",
      "2025-08-26 11:02:43,356 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:43,368 | INFO | Classifying page 16/72...\n",
      "2025-08-26 11:02:44,820 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:44,824 | INFO | Classifying page 17/72...\n",
      "2025-08-26 11:02:45,680 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:45,701 | INFO | Classifying page 18/72...\n",
      "2025-08-26 11:02:47,495 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:47,498 | INFO | Classifying page 19/72...\n",
      "2025-08-26 11:02:48,511 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:48,514 | INFO | Classifying page 20/72...\n",
      "2025-08-26 11:02:49,606 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:49,610 | INFO | Classifying page 21/72...\n",
      "2025-08-26 11:02:50,422 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:50,428 | INFO | Classifying page 22/72...\n",
      "2025-08-26 11:02:51,137 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:51,139 | INFO | Classifying page 23/72...\n",
      "2025-08-26 11:02:52,078 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:52,081 | INFO | Classifying page 24/72...\n",
      "2025-08-26 11:02:52,786 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:52,799 | INFO | Classifying page 25/72...\n",
      "2025-08-26 11:02:53,710 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:53,713 | INFO | Classifying page 26/72...\n",
      "2025-08-26 11:02:54,542 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:54,545 | INFO | Classifying page 27/72...\n",
      "2025-08-26 11:02:55,534 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:55,537 | INFO | Classifying page 28/72...\n",
      "2025-08-26 11:02:56,219 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:56,222 | INFO | Classifying page 29/72...\n",
      "2025-08-26 11:02:57,181 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:57,184 | INFO | Classifying page 30/72...\n",
      "2025-08-26 11:02:57,835 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:57,855 | INFO | Classifying page 31/72...\n",
      "2025-08-26 11:02:58,816 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:02:58,819 | INFO | Classifying page 32/72...\n",
      "2025-08-26 11:02:59,996 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:00,000 | INFO | Classifying page 33/72...\n",
      "2025-08-26 11:03:00,748 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:00,782 | INFO | Classifying page 34/72...\n",
      "2025-08-26 11:03:02,003 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:02,011 | INFO | Classifying page 35/72...\n",
      "2025-08-26 11:03:02,833 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:02,836 | INFO | Classifying page 36/72...\n",
      "2025-08-26 11:03:03,612 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:03,617 | INFO | Classifying page 37/72...\n",
      "2025-08-26 11:03:04,458 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:04,494 | INFO | Classifying page 38/72...\n",
      "2025-08-26 11:03:05,939 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:05,950 | INFO | Classifying page 39/72...\n",
      "2025-08-26 11:03:07,800 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:07,803 | INFO | Classifying page 40/72...\n",
      "2025-08-26 11:03:08,929 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:08,938 | INFO | Classifying page 41/72...\n",
      "2025-08-26 11:03:10,134 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:10,137 | INFO | Classifying page 42/72...\n",
      "2025-08-26 11:03:10,949 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:10,951 | INFO | Classifying page 43/72...\n",
      "2025-08-26 11:03:11,741 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:11,745 | INFO | Classifying page 44/72...\n",
      "2025-08-26 11:03:12,834 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:12,841 | INFO | Classifying page 45/72...\n",
      "2025-08-26 11:03:13,609 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:13,614 | INFO | Classifying page 46/72...\n",
      "2025-08-26 11:03:14,387 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:14,478 | INFO | Classifying page 47/72...\n",
      "2025-08-26 11:03:15,486 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:15,488 | INFO | Classifying page 48/72...\n",
      "2025-08-26 11:03:16,406 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:16,409 | INFO | Classifying page 49/72...\n",
      "2025-08-26 11:03:17,340 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:17,342 | INFO | Classifying page 50/72...\n",
      "2025-08-26 11:03:18,196 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:18,199 | INFO | Classifying page 51/72...\n",
      "2025-08-26 11:03:19,039 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:19,044 | INFO | Classifying page 52/72...\n",
      "2025-08-26 11:03:20,221 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:20,223 | INFO | Classifying page 53/72...\n",
      "2025-08-26 11:03:21,530 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:21,532 | INFO | Classifying page 54/72...\n",
      "2025-08-26 11:03:22,543 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:22,547 | INFO | Classifying page 55/72...\n",
      "2025-08-26 11:03:23,146 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:23,149 | INFO | Classifying page 56/72...\n",
      "2025-08-26 11:03:23,890 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:23,901 | INFO | Classifying page 57/72...\n",
      "2025-08-26 11:03:24,503 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:24,513 | INFO | Classifying page 58/72...\n",
      "2025-08-26 11:03:25,355 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:25,364 | INFO | Classifying page 59/72...\n",
      "2025-08-26 11:03:26,104 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:26,108 | INFO | Classifying page 60/72...\n",
      "2025-08-26 11:03:27,082 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:27,085 | INFO | Classifying page 61/72...\n",
      "2025-08-26 11:03:27,894 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:27,896 | INFO | Classifying page 62/72...\n",
      "2025-08-26 11:03:29,360 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:29,368 | INFO | Classifying page 63/72...\n",
      "2025-08-26 11:03:30,096 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:30,101 | INFO | Classifying page 64/72...\n",
      "2025-08-26 11:03:30,922 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:30,926 | INFO | Classifying page 65/72...\n",
      "2025-08-26 11:03:31,976 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:31,978 | INFO | Classifying page 66/72...\n",
      "2025-08-26 11:03:33,064 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:33,068 | INFO | Classifying page 67/72...\n",
      "2025-08-26 11:03:33,946 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:33,957 | INFO | Classifying page 68/72...\n",
      "2025-08-26 11:03:33,958 | INFO | Classifying page 69/72...\n",
      "2025-08-26 11:03:34,888 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:34,898 | INFO | Classifying page 70/72...\n",
      "2025-08-26 11:03:35,715 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:35,720 | INFO | Classifying page 71/72...\n",
      "2025-08-26 11:03:36,581 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:36,626 | INFO | Classifying page 72/72...\n",
      "2025-08-26 11:03:37,317 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:03:37,346 | INFO | \n",
      "Successfully saved classified text to './Output/classified_pdf_text_aiv2.csv'\n",
      "2025-08-26 11:03:37,346 | INFO | \n",
      "--- Sample of Final Data (text column omitted for brevity) ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   page_number             bucket  confidence                                                                     explanation\n",
      "0            1  table of contents        0.95            Lists sections, rules, forms, and attachments in document structure.\n",
      "1            2  intro information        0.90  Summary of filing requirements and administrative header information provided.\n",
      "2            3  intro information        0.95        Summary of filing details, company, product, and submission information.\n",
      "3            4  intro information        0.95         Contains company info, project details, and filing description summary.\n",
      "4            5  intro information        0.90         Contains filing fees, company info, and administrative details summary.\n"
     ]
    }
   ],
   "source": [
    "# # Pypdf extraction and OpenAI classification script\n",
    "# import pandas as pd\n",
    "# import pypdf\n",
    "# import os\n",
    "# import json\n",
    "# import time\n",
    "# import logging\n",
    "# from openai import OpenAI # Use the updated OpenAI library import\n",
    "# from typing import Dict, Any\n",
    "\n",
    "# # === LOGGING SETUP ===\n",
    "# # Sets up basic configuration for logging messages.\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    "# )\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# # === CONFIGURATION ===\n",
    "# # It's better to manage paths and model names in a central place.\n",
    "# # The API key is read from a local file for better security.\n",
    "# API_KEY_PATH = \"/Users/jake/Documents/Key/OPENAI_KEY.txt\" # <--- ADJUST IF NEEDED\n",
    "# MODEL = \"gpt-4o\" # Using the latest model as specified\n",
    "\n",
    "# def get_openai_client(api_key_path: str) -> OpenAI:\n",
    "#     \"\"\"Reads the OpenAI API key from a file and returns an OpenAI client.\"\"\"\n",
    "#     try:\n",
    "#         with open(api_key_path, 'r') as f:\n",
    "#             api_key = f.read().strip()\n",
    "#         if not api_key:\n",
    "#             raise ValueError(\"API key file is empty.\")\n",
    "#         logger.info(\"Successfully loaded OpenAI API key.\")\n",
    "#         return OpenAI(api_key=api_key)\n",
    "#     except FileNotFoundError:\n",
    "#         logger.error(f\"API key file not found at: {api_key_path}\")\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"An error occurred while reading the API key: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path: str) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Extracts all text from a given PDF file, page by page.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(pdf_path):\n",
    "#         logger.error(f\"Error: File not found at {pdf_path}\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     logger.info(f\"Starting text extraction from '{os.path.basename(pdf_path)}'...\")\n",
    "#     all_pages_data = []\n",
    "\n",
    "#     try:\n",
    "#         with open(pdf_path, 'rb') as file:\n",
    "#             reader = pypdf.PdfReader(file)\n",
    "#             num_pages = len(reader.pages)\n",
    "#             logger.info(f\"Found {num_pages} pages in the document.\")\n",
    "\n",
    "#             for i, page in enumerate(reader.pages):\n",
    "#                 page_number = i + 1\n",
    "#                 text = page.extract_text() or \"\" # Ensure text is a string\n",
    "                \n",
    "#                 all_pages_data.append({\n",
    "#                     'page_number': page_number,\n",
    "#                     'text': text.strip()\n",
    "#                 })\n",
    "#                 if not text.strip():\n",
    "#                     logger.info(f\"  - No text found on page {page_number}.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"An error occurred while processing the PDF: {e}\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     if all_pages_data:\n",
    "#         df = pd.DataFrame(all_pages_data)\n",
    "#         logger.info(\"Text extraction complete.\")\n",
    "#         return df\n",
    "#     else:\n",
    "#         logger.warning(\"Warning: No text was extracted from the document.\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "# def classify_page_text(client: OpenAI, page_number: int, page_text: str) -> Dict[str, Any]:\n",
    "#     \"\"\"\n",
    "#     Classifies the text of a single page using the OpenAI API.\n",
    "#     \"\"\"\n",
    "#     # The new system prompt with updated instructions and JSON format.\n",
    "#     # Note: The model is only asked for classification details.\n",
    "#     # Page number and text are added back into the final dictionary later.\n",
    "#     sys_prompt = \"\"\"\n",
    "# You are an expert insurance regulatory analyst reviewing a state commercial auto insurance rate and rule filing.\n",
    "\n",
    "# Your job is to classify each page into a single best-fitting category (\"bucket\"). The following buckets are examples of likely categories, but you are allowed to invent and assign a new, appropriate bucket name, if the existing examples do not fit.\n",
    "\n",
    "# BUCKET EXAMPLES (use or invent as needed):\n",
    "\n",
    "# - intro information: Cover letters, summaries, company info, administrative headers.\n",
    "# - table of contents: Tables/indexes listing sections, rules, forms.\n",
    "# - correspondence: Letters, memos, formal or informal communication (including with a regulator).\n",
    "# - rule: Detailed rating rules, eligibility, underwriting guidelines, standard operating instructions.\n",
    "# - factor table: Tabular lists of rating factors—e.g. for zones, territories, drivers, vehicles.\n",
    "# - actuarial support: Mathematical or statistical justification, trend documentation, loss ratios, exhibits.\n",
    "# - form: Complete forms, endorsements, schedules, specimen policy wordings.\n",
    "# - rating example: A worked example showing how premium/rate is calculated.\n",
    "# - exhibit: Graphs, charts, additional annotated attachments or appendices.\n",
    "# - crossed_out: (binary) Use ONLY if the entire page is covered with a line, annotated \"withdrawn,\" or has visible strikethrough/crossout. Otherwise, do not use.\n",
    "# - other: Use only if the page fits none of the above and you cannot reasonably propose a more accurate new bucket name.\n",
    "\n",
    "# BUCKET FLEXIBILITY:\n",
    "# - If none of the above buckets are a good fit, make up an appropriate, concise, descriptive bucket name and use it as the \"bucket\". Do NOT use \"llm_new_category\" as a category name—use your proposed name directly (e.g. \"signature page\", \"state certification\", etc).\n",
    "\n",
    "# CATEGORIZATION INSTRUCTIONS:\n",
    "# - Assign exactly one bucket per page.\n",
    "# - Always provide a 10 word \"explanation\" of why you selected—or if new, created—this bucket.\n",
    "# - If \"crossed_out\" is chosen, no substantive explanation is needed—just state \"Entire page was striked out or withdrawn.\"\n",
    "# - Otherwise, explain the dominant content and your reasoning for the bucket chosen in precisely 10 words.\n",
    "\n",
    "# OUTPUT FORMAT (respond with a single valid JSON object only):\n",
    "\n",
    "# {\n",
    "#   \"bucket\": \"<bucket_name>\",\n",
    "#   \"confidence\": <probability 0-1>,\n",
    "#   \"explanation\": \"<10 word explanation of categorization>\"\n",
    "# }\n",
    "\n",
    "# If uncertain, favor \"other\", but prefer to create (with reasoned explanation) a new appropriate bucket when justified.\n",
    "# \"\"\"\n",
    "#     # Create the full result dictionary here, starting with known values.\n",
    "#     # This ensures page_number and text are always present, even on error.\n",
    "#     result_payload = {\n",
    "#         \"page_number\": page_number,\n",
    "#         \"bucket\": \"processing_error\",\n",
    "#         \"confidence\": 0.0,\n",
    "#         \"explanation\": \"An error occurred before the API call.\",\n",
    "#         \"text\": page_text\n",
    "#     }\n",
    "\n",
    "#     if not page_text:\n",
    "#         result_payload.update({\n",
    "#             \"bucket\": \"other\",\n",
    "#             \"confidence\": 1.0,\n",
    "#             \"explanation\": \"Page is blank or contains no extractable text.\"\n",
    "#         })\n",
    "#         return result_payload\n",
    "\n",
    "#     for attempt in range(3): # Retry logic for transient API errors\n",
    "#         try:\n",
    "#             chat_completion = client.chat.completions.create(\n",
    "#                 messages=[\n",
    "#                     {\"role\": \"system\", \"content\": sys_prompt},\n",
    "#                     {\"role\": \"user\", \"content\": page_text[:16000]}, # Increased token limit for gpt-4o\n",
    "#                 ],\n",
    "#                 model=MODEL,\n",
    "#                 response_format={\"type\": \"json_object\"},\n",
    "#                 temperature=0.0,\n",
    "#             )\n",
    "#             response_content = chat_completion.choices[0].message.content\n",
    "#             # Parse the JSON from the model\n",
    "#             api_result = json.loads(response_content)\n",
    "#             # Update the payload with the model's response\n",
    "#             result_payload.update(api_result)\n",
    "#             return result_payload\n",
    "#         except Exception as e:\n",
    "#             logger.warning(f\"API call failed on attempt {attempt + 1} for page {page_number}: {e}. Retrying in {2 ** attempt}s...\")\n",
    "#             time.sleep(2 ** attempt)\n",
    "\n",
    "#     logger.error(f\"API call failed after multiple retries for page {page_number}.\")\n",
    "#     result_payload.update({\n",
    "#         \"bucket\": \"api_error\",\n",
    "#         \"explanation\": \"API call failed after multiple retries.\"\n",
    "#     })\n",
    "#     return result_payload\n",
    "\n",
    "# # --- Main Script Execution ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # --- USER INPUT ---\n",
    "#     input_pdf_path = \"./Inputs/PGR_Ohio_BNIC-134120828_trimmed.pdf\"\n",
    "#     output_csv_path = \"./Output/classified_pdf_text_aiv2.csv\"\n",
    "\n",
    "#     # --- SCRIPT LOGIC ---\n",
    "#     # 1. Initialize OpenAI Client\n",
    "#     openai_client = get_openai_client(API_KEY_PATH)\n",
    "    \n",
    "#     if openai_client:\n",
    "#         # 2. Extract text from PDF\n",
    "#         pdf_dataframe = extract_text_from_pdf(input_pdf_path)\n",
    "\n",
    "#         if not pdf_dataframe.empty:\n",
    "#             # 3. Classify each page\n",
    "#             logger.info(\"Starting page classification process...\")\n",
    "            \n",
    "#             results = []\n",
    "#             total_pages = len(pdf_dataframe)\n",
    "#             for index, row in pdf_dataframe.iterrows():\n",
    "#                 logger.info(f\"Classifying page {row['page_number']}/{total_pages}...\")\n",
    "#                 # Pass page number and text to the classification function\n",
    "#                 result = classify_page_text(\n",
    "#                     client=openai_client, \n",
    "#                     page_number=row['page_number'], \n",
    "#                     page_text=row['text']\n",
    "#                 )\n",
    "#                 results.append(result)\n",
    "\n",
    "#             # 4. Create the final DataFrame from the list of result dictionaries\n",
    "#             final_df = pd.DataFrame(results)\n",
    "\n",
    "#             # 5. Save the final results to CSV\n",
    "#             try:\n",
    "#                 # Reorder columns for clarity in the output CSV\n",
    "#                 column_order = ['page_number', 'bucket', 'confidence', 'explanation', 'text']\n",
    "#                 final_df = final_df[column_order]\n",
    "                \n",
    "#                 final_df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "#                 logger.info(f\"\\nSuccessfully saved classified text to '{output_csv_path}'\")\n",
    "                \n",
    "#                 logger.info(\"\\n--- Sample of Final Data (text column omitted for brevity) ---\")\n",
    "#                 print(final_df.drop(columns=['text']).head().to_string())\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 logger.error(f\"\\nAn error occurred while saving the CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pypdf extraction and OpenAI classification script\n",
    "import pandas as pd\n",
    "import pypdf\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from openai import OpenAI # Use the updated OpenAI library import\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# === LOGGING SETUP ===\n",
    "# Sets up basic configuration for logging messages.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# It's better to manage paths and model names in a central place.\n",
    "# The API key is read from a local file for better security.\n",
    "API_KEY_PATH = \"/Users/jake/Documents/Key/OPENAI_KEY.txt\" # <--- ADJUST IF NEEDED\n",
    "MODEL = \"gpt-4o\" # Using the latest model as specified\n",
    "\n",
    "def get_openai_client(api_key_path: str) -> OpenAI:\n",
    "    \"\"\"Reads the OpenAI API key from a file and returns an OpenAI client.\"\"\"\n",
    "    try:\n",
    "        with open(api_key_path, 'r') as f:\n",
    "            api_key = f.read().strip()\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API key file is empty.\")\n",
    "        logger.info(\"Successfully loaded OpenAI API key.\")\n",
    "        return OpenAI(api_key=api_key)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"API key file not found at: {api_key_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while reading the API key: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts all text from a given PDF file, page by page.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        logger.error(f\"Error: File not found at {pdf_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Starting text extraction from '{os.path.basename(pdf_path)}'...\")\n",
    "    all_pages_data = []\n",
    "\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = pypdf.PdfReader(file)\n",
    "            num_pages = len(reader.pages)\n",
    "            logger.info(f\"Found {num_pages} pages in the document.\")\n",
    "\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                page_number = i + 1\n",
    "                text = page.extract_text() or \"\" # Ensure text is a string\n",
    "                \n",
    "                all_pages_data.append({\n",
    "                    'page_number': page_number,\n",
    "                    'text': text.strip()\n",
    "                })\n",
    "                if not text.strip():\n",
    "                    logger.info(f\"  - No text found on page {page_number}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while processing the PDF: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if all_pages_data:\n",
    "        df = pd.DataFrame(all_pages_data)\n",
    "        logger.info(\"Text extraction complete.\")\n",
    "        return df\n",
    "    else:\n",
    "        logger.warning(\"Warning: No text was extracted from the document.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def classify_page_text(client: OpenAI, page_number: int, page_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Classifies the text of a single page using the OpenAI API.\n",
    "    \"\"\"\n",
    "    # The new system prompt with updated instructions and JSON format.\n",
    "    # Note: The model is only asked for classification details.\n",
    "    # Page number and text are added back into the final dictionary later.\n",
    "    sys_prompt = \"\"\"\n",
    "You are an expert insurance regulatory analyst reviewing a state commercial auto insurance rate and rule filing.\n",
    "\n",
    "Your job is to classify each page into a single best-fitting category (\"bucket\"). The following buckets are examples of likely categories, but you are allowed to invent and assign a new, appropriate bucket name, if the existing examples do not fit.\n",
    "\n",
    "BUCKET EXAMPLES (use or invent as needed):\n",
    "\n",
    "- intro information: Cover letters, summaries, company info, administrative headers.\n",
    "- table of contents: Tables/indexes listing sections, rules, forms.\n",
    "- correspondence: Letters, memos, formal or informal communication (including with a regulator).\n",
    "- rule: Detailed rating rules, eligibility, underwriting guidelines, standard operating instructions.\n",
    "- factor_table: Tabular lists of rating factors—e.g. for zones, territories, drivers, vehicles.\n",
    "- actuarial support: Mathematical or statistical justification, trend documentation, loss ratios, exhibits.\n",
    "- form: Complete forms, endorsements, schedules, specimen policy wordings.\n",
    "- rating example: A worked example showing how premium/rate is calculated.\n",
    "- exhibit: Graphs, charts, additional annotated attachments or appendices.\n",
    "- crossed_out: (binary) Use ONLY if the entire page is covered with a line, annotated \"withdrawn,\" or has visible strikrough/crossout. Otherwise, do not use.\n",
    "- other: Use only if the page fits none of the above and you cannot reasonably propose a more accurate new bucket name.\n",
    "\n",
    "BUCKET FLEXIBILITY:\n",
    "- If none of the above buckets are a good fit, make up an appropriate, concise, descriptive bucket name and use it as the \"bucket\". Do NOT use \"llm_new_category\" as a category name—use your proposed name directly (e.g. \"signature page\", \"state certification\", etc).\n",
    "\n",
    "CATEGORIZATION INSTRUCTIONS:\n",
    "- Assign exactly one bucket per page.\n",
    "- Always provide a 10 word \"explanation\" of why you selected—or if new, created—this bucket.\n",
    "- If \"crossed_out\" is chosen, no substantive explanation is needed—just state \"Entire page was striked out or withdrawn.\"\n",
    "- Otherwise, explain the dominant content and your reasoning for the bucket chosen in precisely 10 words.\n",
    "\n",
    "OUTPUT FORMAT (respond with a single valid JSON object only):\n",
    "\n",
    "{\n",
    "  \"bucket\": \"<bucket_name>\",\n",
    "  \"confidence\": <probability 0-1>,\n",
    "  \"explanation\": \"<10 word explanation of categorization>\"\n",
    "}\n",
    "\n",
    "If uncertain, favor \"other\", but prefer to create (with reasoned explanation) a new appropriate bucket when justified.\n",
    "\"\"\"\n",
    "    # Create the full result dictionary here, starting with known values.\n",
    "    # This ensures page_number and text are always present, even on error.\n",
    "    result_payload = {\n",
    "        \"page_number\": page_number,\n",
    "        \"bucket\": \"processing_error\",\n",
    "        \"confidence\": 0.0,\n",
    "        \"explanation\": \"An error occurred before the API call.\",\n",
    "        \"text\": page_text\n",
    "    }\n",
    "\n",
    "    if not page_text:\n",
    "        result_payload.update({\n",
    "            \"bucket\": \"other\",\n",
    "            \"confidence\": 1.0,\n",
    "            \"explanation\": \"Page is blank or contains no extractable text.\"\n",
    "        })\n",
    "        return result_payload\n",
    "\n",
    "    for attempt in range(3): # Retry logic for transient API errors\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                    {\"role\": \"user\", \"content\": page_text[:16000]}, # Increased token limit for gpt-4o\n",
    "                ],\n",
    "                model=MODEL,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            response_content = chat_completion.choices[0].message.content\n",
    "            # Parse the JSON from the model\n",
    "            api_result = json.loads(response_content)\n",
    "            # Update the payload with the model's response\n",
    "            result_payload.update(api_result)\n",
    "            return result_payload\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"API call failed on attempt {attempt + 1} for page {page_number}: {e}. Retrying in {2 ** attempt}s...\")\n",
    "            time.sleep(2 ** attempt)\n",
    "\n",
    "    logger.error(f\"API call failed after multiple retries for page {page_number}.\")\n",
    "    result_payload.update({\n",
    "        \"bucket\": \"api_error\",\n",
    "        \"explanation\": \"API call failed after multiple retries.\"\n",
    "    })\n",
    "    return result_payload\n",
    "\n",
    "def extract_and_structure_table(client: OpenAI, table_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Uses the AI to extract a title and structured data from table text.\n",
    "    \"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "You are an expert data extraction assistant. Your task is to analyze the provided text, which contains one or more pages of a factor table from an insurance filing.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1.  **Identify the Table Title**: Find the most appropriate title for the table. This is often at the top of the first page. If no clear title exists, create a concise, descriptive one.\n",
    "2.  **Recreate the Table**: Parse the text to reconstruct the table's data, including headers.\n",
    "3.  **Handle Multi-Page Tables**: The text may come from multiple pages. You must intelligently stitch together table parts. The start of a new page might not have headers; in this case, you should continue the table from the previous page.\n",
    "4.  **Return JSON**: Your output must be a single, valid JSON object with the following structure:\n",
    "    {\n",
    "      \"table_title\": \"<The title you identified or created>\",\n",
    "      \"table_data\": [\n",
    "        [\"Header 1\", \"Header 2\", \"Header 3\"],\n",
    "        [\"Row 1 Col 1\", \"Row 1 Col 2\", \"Row 1 Col 3\"],\n",
    "        [\"Row 2 Col 1\", \"Row 2 Col 2\", \"Row 2 Col 3\"]\n",
    "      ]\n",
    "    }\n",
    "\"\"\"\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": table_text},\n",
    "            ],\n",
    "            model=MODEL,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        response_content = chat_completion.choices[0].message.content\n",
    "        return json.loads(response_content)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during table extraction: {e}\")\n",
    "        return {\n",
    "            \"table_title\": \"Extraction Error\",\n",
    "            \"table_data\": [[f\"An error occurred: {e}\"]]\n",
    "        }\n",
    "\n",
    "def process_factor_tables(client: OpenAI, classified_df: pd.DataFrame, output_excel_path: str):\n",
    "    \"\"\"\n",
    "    Finds, groups, and extracts factor tables into a multi-sheet Excel file.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting Step 2: Processing 'factor_table' pages...\")\n",
    "    \n",
    "    factor_table_pages = classified_df[classified_df['bucket'] == 'factor_table']\n",
    "    if factor_table_pages.empty:\n",
    "        logger.info(\"No pages were classified as 'factor_table'. Skipping table extraction.\")\n",
    "        return\n",
    "\n",
    "    # Use ExcelWriter to save multiple sheets to one file\n",
    "    with pd.ExcelWriter(output_excel_path, engine='openpyxl') as writer:\n",
    "        # Group consecutive pages classified as factor tables\n",
    "        page_indices = factor_table_pages.index\n",
    "        if not page_indices.any():\n",
    "            return\n",
    "            \n",
    "        current_group = [page_indices[0]]\n",
    "        for i in range(1, len(page_indices)):\n",
    "            # If the current page is not consecutive with the previous one, process the completed group\n",
    "            if page_indices[i] != page_indices[i-1] + 1:\n",
    "                process_table_group(client, classified_df, current_group, writer)\n",
    "                current_group = []\n",
    "            current_group.append(page_indices[i])\n",
    "        \n",
    "        # Process the last group\n",
    "        if current_group:\n",
    "            process_table_group(client, classified_df, current_group, writer)\n",
    "\n",
    "    logger.info(f\"Successfully saved extracted tables to '{output_excel_path}'\")\n",
    "\n",
    "def process_table_group(client: OpenAI, df: pd.DataFrame, group_indices: List[int], writer: pd.ExcelWriter):\n",
    "    \"\"\"\n",
    "    Processes a single group of consecutive factor table pages.\n",
    "    \"\"\"\n",
    "    page_numbers = df.loc[group_indices, 'page_number'].tolist()\n",
    "    logger.info(f\"Processing a potential table spanning pages: {page_numbers}\")\n",
    "    \n",
    "    # Concatenate the text from all pages in the group\n",
    "    combined_text = \"\\n--- NEW PAGE BREAK ---\\n\".join(df.loc[group_indices, 'text'])\n",
    "    \n",
    "    # Send the combined text to the AI for structuring\n",
    "    structured_table = extract_and_structure_table(client, combined_text)\n",
    "    \n",
    "    table_title = structured_table.get(\"table_title\", \"Untitled Table\")\n",
    "    table_data = structured_table.get(\"table_data\", [])\n",
    "    \n",
    "    if table_data:\n",
    "        # Sanitize sheet title to be valid in Excel\n",
    "        safe_sheet_name = \"\".join(c for c in table_title if c.isalnum() or c in (' ', '_')).rstrip()\n",
    "        safe_sheet_name = safe_sheet_name[:31] # Max sheet name length is 31 chars\n",
    "        \n",
    "        # Convert the structured data to a DataFrame and save to a sheet\n",
    "        table_df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "        table_df.to_excel(writer, sheet_name=safe_sheet_name, index=False)\n",
    "        logger.info(f\"  - Saved table '{table_title}' to sheet '{safe_sheet_name}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aeaf17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 11:09:59,380 | INFO | Successfully loaded OpenAI API key.\n",
      "2025-08-26 11:09:59,408 | INFO | Starting text extraction from 'PGR_Ohio_BNIC-134120828_trimmed.pdf'...\n",
      "2025-08-26 11:09:59,421 | INFO | Found 72 pages in the document.\n",
      "2025-08-26 11:10:00,163 | INFO |   - No text found on page 68.\n",
      "2025-08-26 11:10:00,185 | INFO | Text extraction complete.\n",
      "2025-08-26 11:10:00,185 | INFO | Starting Step 1: Page classification...\n",
      "2025-08-26 11:10:00,186 | INFO | Classifying page 1/72...\n",
      "2025-08-26 11:10:01,135 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:01,140 | INFO | Classifying page 2/72...\n",
      "2025-08-26 11:10:01,806 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:01,818 | INFO | Classifying page 3/72...\n",
      "2025-08-26 11:10:02,889 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:02,894 | INFO | Classifying page 4/72...\n",
      "2025-08-26 11:10:03,972 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:03,975 | INFO | Classifying page 5/72...\n",
      "2025-08-26 11:10:04,811 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:04,815 | INFO | Classifying page 6/72...\n",
      "2025-08-26 11:10:05,638 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:05,649 | INFO | Classifying page 7/72...\n",
      "2025-08-26 11:10:07,306 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:07,308 | INFO | Classifying page 8/72...\n",
      "2025-08-26 11:10:08,116 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:08,118 | INFO | Classifying page 9/72...\n",
      "2025-08-26 11:10:08,840 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:08,848 | INFO | Classifying page 10/72...\n",
      "2025-08-26 11:10:09,730 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:09,738 | INFO | Classifying page 11/72...\n",
      "2025-08-26 11:10:10,601 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:10,606 | INFO | Classifying page 12/72...\n",
      "2025-08-26 11:10:11,316 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:11,330 | INFO | Classifying page 13/72...\n",
      "2025-08-26 11:10:12,206 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:12,213 | INFO | Classifying page 14/72...\n",
      "2025-08-26 11:10:13,441 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:13,454 | INFO | Classifying page 15/72...\n",
      "2025-08-26 11:10:14,590 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:14,599 | INFO | Classifying page 16/72...\n",
      "2025-08-26 11:10:15,377 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:15,381 | INFO | Classifying page 17/72...\n",
      "2025-08-26 11:10:16,535 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:16,542 | INFO | Classifying page 18/72...\n",
      "2025-08-26 11:10:17,286 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:17,288 | INFO | Classifying page 19/72...\n",
      "2025-08-26 11:10:17,994 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:17,997 | INFO | Classifying page 20/72...\n",
      "2025-08-26 11:10:18,825 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:18,832 | INFO | Classifying page 21/72...\n",
      "2025-08-26 11:10:19,496 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:19,500 | INFO | Classifying page 22/72...\n",
      "2025-08-26 11:10:20,162 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:20,168 | INFO | Classifying page 23/72...\n",
      "2025-08-26 11:10:20,866 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:20,870 | INFO | Classifying page 24/72...\n",
      "2025-08-26 11:10:21,913 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:21,918 | INFO | Classifying page 25/72...\n",
      "2025-08-26 11:10:22,573 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:22,575 | INFO | Classifying page 26/72...\n",
      "2025-08-26 11:10:23,274 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:23,275 | INFO | Classifying page 27/72...\n",
      "2025-08-26 11:10:24,498 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:24,501 | INFO | Classifying page 28/72...\n",
      "2025-08-26 11:10:25,573 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:25,578 | INFO | Classifying page 29/72...\n",
      "2025-08-26 11:10:26,354 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:26,363 | INFO | Classifying page 30/72...\n",
      "2025-08-26 11:10:27,084 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:27,088 | INFO | Classifying page 31/72...\n",
      "2025-08-26 11:10:27,810 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:27,813 | INFO | Classifying page 32/72...\n",
      "2025-08-26 11:10:28,691 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:28,695 | INFO | Classifying page 33/72...\n",
      "2025-08-26 11:10:29,411 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:29,414 | INFO | Classifying page 34/72...\n",
      "2025-08-26 11:10:30,082 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:30,086 | INFO | Classifying page 35/72...\n",
      "2025-08-26 11:10:30,798 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:30,807 | INFO | Classifying page 36/72...\n",
      "2025-08-26 11:10:31,446 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:31,448 | INFO | Classifying page 37/72...\n",
      "2025-08-26 11:10:32,129 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:32,139 | INFO | Classifying page 38/72...\n",
      "2025-08-26 11:10:32,930 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:32,942 | INFO | Classifying page 39/72...\n",
      "2025-08-26 11:10:33,708 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:33,711 | INFO | Classifying page 40/72...\n",
      "2025-08-26 11:10:34,395 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:34,399 | INFO | Classifying page 41/72...\n",
      "2025-08-26 11:10:35,234 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:35,237 | INFO | Classifying page 42/72...\n",
      "2025-08-26 11:10:35,977 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:35,992 | INFO | Classifying page 43/72...\n",
      "2025-08-26 11:10:36,818 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:36,820 | INFO | Classifying page 44/72...\n",
      "2025-08-26 11:10:37,483 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:37,488 | INFO | Classifying page 45/72...\n",
      "2025-08-26 11:10:38,382 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:38,388 | INFO | Classifying page 46/72...\n",
      "2025-08-26 11:10:39,135 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:39,139 | INFO | Classifying page 47/72...\n",
      "2025-08-26 11:10:39,986 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:39,989 | INFO | Classifying page 48/72...\n",
      "2025-08-26 11:10:40,792 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:40,794 | INFO | Classifying page 49/72...\n",
      "2025-08-26 11:10:41,763 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:41,767 | INFO | Classifying page 50/72...\n",
      "2025-08-26 11:10:42,868 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:42,871 | INFO | Classifying page 51/72...\n",
      "2025-08-26 11:10:43,685 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:43,691 | INFO | Classifying page 52/72...\n",
      "2025-08-26 11:10:44,502 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:44,506 | INFO | Classifying page 53/72...\n",
      "2025-08-26 11:10:45,144 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:45,148 | INFO | Classifying page 54/72...\n",
      "2025-08-26 11:10:46,108 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:46,111 | INFO | Classifying page 55/72...\n",
      "2025-08-26 11:10:46,816 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:46,819 | INFO | Classifying page 56/72...\n",
      "2025-08-26 11:10:47,570 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:47,576 | INFO | Classifying page 57/72...\n",
      "2025-08-26 11:10:48,117 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:48,120 | INFO | Classifying page 58/72...\n",
      "2025-08-26 11:10:48,840 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:48,849 | INFO | Classifying page 59/72...\n",
      "2025-08-26 11:10:49,431 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:49,434 | INFO | Classifying page 60/72...\n",
      "2025-08-26 11:10:50,231 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:50,236 | INFO | Classifying page 61/72...\n",
      "2025-08-26 11:10:51,000 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:51,003 | INFO | Classifying page 62/72...\n",
      "2025-08-26 11:10:51,961 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:51,984 | INFO | Classifying page 63/72...\n",
      "2025-08-26 11:10:52,619 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:52,624 | INFO | Classifying page 64/72...\n",
      "2025-08-26 11:10:53,647 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:53,654 | INFO | Classifying page 65/72...\n",
      "2025-08-26 11:10:54,433 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:54,443 | INFO | Classifying page 66/72...\n",
      "2025-08-26 11:10:55,245 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:55,260 | INFO | Classifying page 67/72...\n",
      "2025-08-26 11:10:56,021 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:56,027 | INFO | Classifying page 68/72...\n",
      "2025-08-26 11:10:56,028 | INFO | Classifying page 69/72...\n",
      "2025-08-26 11:10:56,747 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:56,749 | INFO | Classifying page 70/72...\n",
      "2025-08-26 11:10:58,006 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:58,010 | INFO | Classifying page 71/72...\n",
      "2025-08-26 11:10:59,418 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:10:59,423 | INFO | Classifying page 72/72...\n",
      "2025-08-26 11:11:00,124 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-26 11:11:00,137 | INFO | \n",
      "Successfully saved classified text to './Output/classified_pdf_text_trimmed_v3.csv'\n",
      "2025-08-26 11:11:00,138 | INFO | \n",
      "--- Sample of Classification Data (text column omitted for brevity) ---\n",
      "2025-08-26 11:11:00,142 | INFO | Starting Step 2: Processing 'factor_table' pages...\n",
      "2025-08-26 11:11:00,145 | INFO | No pages were classified as 'factor_table'. Skipping table extraction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   page_number             bucket  confidence                                                                         explanation\n",
      "0            1  table of contents        0.95                      Lists sections, rules, forms, and attachments in the document.\n",
      "1            2  intro information        0.90    Summary of filing requirements and administrative tracking information provided.\n",
      "2            3  intro information        0.95  Contains filing overview, company details, and administrative information summary.\n",
      "3            4  intro information        0.95             Contains company info, project details, and filing description summary.\n",
      "4            5  intro information        0.90            Contains filing fees, company info, and administrative tracking details.\n"
     ]
    }
   ],
   "source": [
    "# --- Main Script Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- USER INPUT ---\n",
    "    input_pdf_path = \"./Inputs/PGR_Ohio_BNIC-134120828_trimmed.pdf\"\n",
    "    output_csv_path = \"./Output/classified_pdf_text_trimmed_v3.csv\"\n",
    "    output_excel_path = \"./Output/extracted_factor_tables.xlsx\" # New output for tables\n",
    "\n",
    "    # --- SCRIPT LOGIC ---\n",
    "    # 1. Initialize OpenAI Client\n",
    "    openai_client = get_openai_client(API_KEY_PATH)\n",
    "    \n",
    "    if openai_client:\n",
    "        # 2. Extract text from PDF\n",
    "        pdf_dataframe = extract_text_from_pdf(input_pdf_path)\n",
    "\n",
    "        if not pdf_dataframe.empty:\n",
    "            # 3. Classify each page\n",
    "            logger.info(\"Starting Step 1: Page classification...\")\n",
    "            \n",
    "            results = []\n",
    "            total_pages = len(pdf_dataframe)\n",
    "            for index, row in pdf_dataframe.iterrows():\n",
    "                logger.info(f\"Classifying page {row['page_number']}/{total_pages}...\")\n",
    "                result = classify_page_text(\n",
    "                    client=openai_client, \n",
    "                    page_number=row['page_number'], \n",
    "                    page_text=row['text']\n",
    "                )\n",
    "                results.append(result)\n",
    "\n",
    "            # 4. Create the final DataFrame from the list of result dictionaries\n",
    "            final_df = pd.DataFrame(results)\n",
    "\n",
    "            # 5. Save the classification results to CSV\n",
    "            try:\n",
    "                column_order = ['page_number', 'bucket', 'confidence', 'explanation', 'text']\n",
    "                final_df_ordered = final_df.reindex(columns=column_order)\n",
    "                \n",
    "                final_df_ordered.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "                logger.info(f\"\\nSuccessfully saved classified text to '{output_csv_path}'\")\n",
    "                \n",
    "                logger.info(\"\\n--- Sample of Classification Data (text column omitted for brevity) ---\")\n",
    "                print(final_df_ordered.drop(columns=['text']).head().to_string())\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"\\nAn error occurred while saving the CSV file: {e}\")\n",
    "            \n",
    "            # 6. Process the factor tables into an Excel file\n",
    "            process_factor_tables(openai_client, final_df, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
